# ğŸ§  GradCAM + ResNet for Multi-Label Chest X-Ray Diagnosis

### A Visual Explanation Tool for Medical AI Models

> ğŸš€ Built with PyTorch, MedMNIST, and GradCAM â€” June 2025

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](link-to-your-notebook)
![Made with PyTorch](https://img.shields.io/badge/Made%20with-PyTorch-red?logo=pytorch)
![GradCAM](https://img.shields.io/badge/Visualized-With%20GradCAM-blue)

---

## ğŸ“Œ Overview

This project showcases a deep learning pipeline designed to classify chest X-ray scans using a convolutional neural network (ResNet-18) while offering explainable model insights through GradCAM visualizations.

Chest diseases like infiltration, pneumonia, and nodules often coexist in medical scans, requiring a **multi-label classification approach** rather than simple binary or multiclass prediction. This is addressed using the **ChestMNIST** dataset â€” a curated, medically annotated subset of the MedMNIST v2 collection â€” that consists of grayscale chest X-ray images labeled with up to 14 diagnostic tags per image.

Beyond classification, the key goal of this project is to make the modelâ€™s decisions **interpretable and trustworthy**. In high-stakes domains like healthcare, it's not enough for AI to be accurate â€” it must also be explainable. GradCAM (Gradient-weighted Class Activation Mapping) fills this gap by generating heatmaps over images to show **what parts of the input influenced the modelâ€™s prediction**.

This repo is intended for researchers, practitioners, and students interested in combining medical image classification with XAI (Explainable AI) techniques.

---

## ğŸ’¡ Key Features

- ğŸ§  Trains a **ResNet-18 model** on ChestMNIST with multi-label binary cross-entropy loss
- ğŸ§ª Performs evaluation on a test set with metrics like accuracy, AUROC, and loss
- ğŸ” Visualizes GradCAM overlays to reveal regions the model deems important
- ğŸ¥ Generates animated GIFs of raw vs. heatmapped predictions
- ğŸ“Š Clean, modular Jupyter notebooks for training and visualization

---

## ğŸ”§ Tech Stack

- **Languages & Libraries**: Python, PyTorch, torchvision, timm, matplotlib
- **Data Source**: ChestMNIST via `medmnist` loader
- **Model**: Pretrained ResNet-18, adapted for 1-channel grayscale inputs
- **Visualization**: GradCAM (from [`pytorch-grad-cam`](https://github.com/jacobgil/pytorch-grad-cam)), image overlays, and animations
- **Environment**: Google Colab or local (CPU/GPU)

---

## ğŸ¥ GradCAM in Action

<p align="center">
  <img src="assets/images/image.png" width="45%" />
</p>

> These examples show how GradCAM overlays attention maps on top of chest X-rays, giving us a transparent look into model decisions.

---

## ğŸ§ª How to Run

1. Clone the repository:
```bash
git clone https://github.com/aryanjain00/gradcam-chestxray
cd gradcam-chestxray
```

2. (Optional) Create a virtual environment:
```bash
conda create -n gradcam-env python=3.9
conda activate gradcam-env
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Launch the Jupyter notebook:
```bash
jupyter notebook train_model.ipynb
```

Or run it fully in Google Colab using the button above â˜ï¸

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ train_model.ipynb         # Training pipeline
â”œâ”€â”€ gradcam_visualizer.ipynb  # GradCAM generation notebook
â”œâ”€â”€ assets/                   # Static images, GIFs, heatmaps
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ requirements.txt          # Dependencies
```

---

## ğŸ“ˆ Model Results

After training for several epochs on a GPU-backed runtime:
- ğŸ¯ Loss converges with multi-label BCE loss
- ğŸ“Š AUROC scores are strong across common diagnoses
- ğŸ§  Heatmaps from GradCAM correlate visually with visible anomalies in some test cases

This is intended as a **prototype and educational demo** â€” not a clinical-grade system.

---

## âš•ï¸ Real-World Use Case

Explainable deep learning is increasingly essential in healthcare, especially in radiology. A model that performs well but is a black box is difficult to trust in a clinical setting.

This workflow mimics what hospitals might eventually use:
- Input X-ray â†’ Classifier â†’ Prediction + Justification (via GradCAM)
- Human-in-the-loop validation by doctors
- Regulatory alignment through interpretability

---

## ğŸ§‘â€ğŸ’» Author

**Aryan Jain**  
M.Sc. Artificial Intelligence @ Deggendorf Institute of Technology  
ğŸ“« [LinkedIn](https://www.linkedin.com/in/aryan-jain-5b2634136/)  

---

## ğŸ“œ License

MIT License. You are free to fork, adapt, and build on top of this work â€” attribution appreciated.

---

**Built with â¤ï¸ to support transparency in medical AI.**